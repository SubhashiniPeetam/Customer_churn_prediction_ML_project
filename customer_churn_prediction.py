# -*- coding: utf-8 -*-
"""Customer_churn_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19GI6YIAfcnJlZpjsM7MUNaTbTIjYsmaS

1. Data Collection
2. EDA
3. Data Preprocessing
4. Train-Test-Split
5. Ml Models
6. Unknown dataset-ml model-prediction

**1. Importing the libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pickle

"""**2. Data loading and understanding the data**"""

df = pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")

df.head()

df.shape

pd.set_option("display.max_columns", None)

df.head(5)

df.info()

"""dropping customer id column"""

df=df.drop(columns=["customerID"])

df.head(2)

df.info()

"""printing unique values in all the columns to know wether the columns are numerical columns are categorical columns"""

df.columns

print(df["gender"].unique())

print(df["SeniorCitizen"].unique())

for col in df.columns:
  print(col,df[col].unique())
  print("*"*50)

df[df["TotalCharges"]==" "]

len(df[df["TotalCharges"]==" "])

"""replacing ' ' wwith 0 in totalcharges column"""

df["TotalCharges"]=df["TotalCharges"].replace(' ',"0.0")

len(df[df["TotalCharges"]=="0.0"])

"""converting total charges column into float as it is in string


"""

df["TotalCharges"]=df["TotalCharges"].astype(float)

df.info()

df.isnull().sum()

#checking the class distribution of target column churn
df["Churn"].value_counts()

"""**insights**

1. Removed CustomerId column
2. No missing values in the dataset
3. Replaced missing values of totalcharges column with 0.0 as we converted into float
4. class imbalance identified in the target column
"""

df.shape

df.columns

df.head(4)

df.describe()

df.info()

"""Numerical feature Analysis"""

#understand the distribution of numerical columns
def plot_columns(df,column_name):
  plt.figure(figsize=(5,3))
  sns.histplot(df[column_name],kde=True)
  plt.title(f"Distribution of {column_name}")
  #calculate the mean and median
  column_mean=df[column_name].mean()
  column_median=df[column_name].median()

  #add vertcal lines for mean and median
  plt.axvline(column_mean,color="red", linestyle="--",linewidth=1,label="Mean")
  plt.axvline(column_median,color="blue",linestyle="-",linewidth=1,label="Median")
  plt.legend()
  plt.show()

plot_columns(df,"tenure")

plot_columns(df,"MonthlyCharges")

plot_columns(df,"TotalCharges")

"""**Box plot for numerical featured to find outliers**"""

def plot_boxplot(df,column_name):
  plt.figure(figsize=(5,3))
  sns.boxplot(y=df[column_name])
  plt.title(f"Box plot of {column_name}")
  plt.ylabel(column_name)
  plt.show()

plot_boxplot(df,"tenure")

plot_boxplot(df,"MonthlyCharges")

plot_boxplot(df,"TotalCharges")

"""Correlatio heatmap for numerical columns"""

plt.figure(figsize=(5,3))
sns.heatmap(df[["tenure","MonthlyCharges","TotalCharges"]].corr(),annot=True,cmap="coolwarm",fmt=".2f")
plt.title("Correlation heatmap")
plt.show()

"""categorical features analysis"""

df.columns

df.info()

object_columns=df.select_dtypes(include="object").columns.to_list()
print(object_columns)
object_columns+=["SeniorCitizen"]
print(object_columns)

"""count plot for categorical columns"""

for column in object_columns:
  plt.figure(figsize=(5,3))
  sns.countplot(x=df[column])
  plt.title(f"Count plot for {column}")
  plt.show()

"""Data Preprocessing"""

df.head(4)

"""Label encoding of target column"""

df["Churn"]=df["Churn"].replace({"Yes":1,"No":0})

df.head(3)

df["Churn"].value_counts()

"""Label encoding of categorical columns"""

#identifying columns with object type
object_columns = df.select_dtypes(include="object").columns.to_list()
print(object_columns)

#dictionary to save the encoders
encoders = {}
for column in object_columns:
  label_encoder=LabelEncoder()
  df[column]=label_encoder.fit_transform(df[column])
  encoders[column]=label_encoder

encoders

#save the encoders to a pickle file
with open("encoders.pkl","wb") as f:
  pickle.dump(encoders,f)

df.head()

"""**Training and test split**"""

x=df.drop(columns=["Churn"])
y=df["Churn"]

x.head(10)

"""Split training and testing data"""

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

y_train.shape

y_train.value_counts()

"""Now performing imbalance

Synthetic Minority Oversampling TEchnique(SMOTE)
"""

smote=SMOTE(random_state=42)
#sampling is done only on test data
x_train_smote,y_train_smote=smote.fit_resample(x_train,y_train)

y_train_smote.shape

y_train_smote.value_counts()

"""5. Model Training"""

#dictionary of models
models={"Decision Tree":DecisionTreeClassifier(random_state=42),
        "random forest":RandomForestClassifier(random_state=42),
        "XGBoost":XGBClassifier(random_state=42)}

#dictionary to store cross validation results
cv_scores={}
for model_name,model in models.items():
  print(model_name)
  print(model)
  print("-"*50)

for model_name,model in models.items():
  print(f"Training {model_name} with default parameters")
  scores=cross_val_score(model,x_train_smote,y_train_smote,cv=5,scoring="accuracy")
  cv_scores[model_name]=scores
  print(f"{model_name} cross validation accuracy is {np.mean(scores):.2f} ")
  print("-"*50)

cv_scores

"""Random forest gives the highest accuracy compared with other models with default parameters"""

rfc=RandomForestClassifier(random_state=42)

rfc.fit(x_train_smote,y_train_smote)

"""6. Model Evaluation"""

y_test_pred=model.predict(x_test)
print("Accuracy SCore:",accuracy_score(y_test,y_test_pred))
print("Confusion Matrix:",confusion_matrix(y_test,y_test_pred))
print("Classification Report:",classification_report(y_test,y_test_pred))

#save the trained model as a pickle file
model_data={"model":rfc,"feature_names":x.columns.to_list()}
with open("customer churn model.pkl","wb") as f:
  pickle.dump(model_data,f)

"""7.Load the saved model and build a predictive system"""

with open("customer churn model.pkl","rb") as f:
  model_data=pickle.load(f)
loaded_model=model_data["model"]
feature_names=model_data["feature_names"]

print(loaded_model)

print(feature_names)

input_data = {
    'gender': 'Female',
    'SeniorCitizen': 0,
    'Partner': 'Yes',
    'Dependents': 'No',
    'tenure': 1,
    'PhoneService': 'No',
    'MultipleLines': 'No phone service',
    'InternetService': 'DSL',
    'OnlineSecurity': 'No',
    'OnlineBackup': 'Yes',
    'DeviceProtection': 'No',
    'TechSupport': 'No',
    'StreamingTV': 'No',
    'StreamingMovies': 'No',
    'Contract': 'Month-to-month',
    'PaperlessBilling': 'Yes',
    'PaymentMethod': 'Electronic check',
    'MonthlyCharges': 29.85,
    'TotalCharges': 29.85
}


input_data_df = pd.DataFrame([input_data])

with open("encoders.pkl", "rb") as f:
  encoders = pickle.load(f)


# encode categorical featires using teh saved encoders
for column, encoder in encoders.items():
  input_data_df[column] = encoder.transform(input_data_df[column])

# make a prediction
prediction = loaded_model.predict(input_data_df)
pred_prob = loaded_model.predict_proba(input_data_df)

print(prediction)

# results
print(f"Prediction: {'Churn' if prediction[0] == 1 else 'No Churn'}")
print(f"Prediciton Probability: {pred_prob}")